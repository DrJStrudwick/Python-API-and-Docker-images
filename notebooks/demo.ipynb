{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have 2 main parts. \n",
    "\n",
    "- Part 1 - Api for a SKL pipline\n",
    "- Part 2 - Make a docker image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Api for a SKL pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we shall\n",
    "- Import libraries and create the model\n",
    "- Export pipline & Test load\n",
    "- Test prediction for API verification\n",
    "- Building the flask app file\n",
    "- Test hitting the running API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo rather than just putting a model into an API we shall be putting a whole pipeline into one. In other words we shall just send raw data to the API and any pre-processing, feature engieering will also be done as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pickle\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we shall be using is a sample dataset downloaded from somewhere on the internet. This isn't meant to be used for anything other than demonstrations purposes. \n",
    "\n",
    "We shall be building a simple linear regression, where the feature we are trying to predict is \"charges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"../data/datasets_13720_18513_insurance.csv\")    #read in the csv to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  #a quick look at the head of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes    #check the data types of the columns read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338</td>\n",
       "      <td>1338</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1064</td>\n",
       "      <td>364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age   sex          bmi     children smoker     region  \\\n",
       "count   1338.000000  1338  1338.000000  1338.000000   1338       1338   \n",
       "unique          NaN     2          NaN          NaN      2          4   \n",
       "top             NaN  male          NaN          NaN     no  southeast   \n",
       "freq            NaN   676          NaN          NaN   1064        364   \n",
       "mean      39.207025   NaN    30.663397     1.094918    NaN        NaN   \n",
       "std       14.049960   NaN     6.098187     1.205493    NaN        NaN   \n",
       "min       18.000000   NaN    15.960000     0.000000    NaN        NaN   \n",
       "25%       27.000000   NaN    26.296250     0.000000    NaN        NaN   \n",
       "50%       39.000000   NaN    30.400000     1.000000    NaN        NaN   \n",
       "75%       51.000000   NaN    34.693750     2.000000    NaN        NaN   \n",
       "max       64.000000   NaN    53.130000     5.000000    NaN        NaN   \n",
       "\n",
       "             charges  \n",
       "count    1338.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean    13270.422265  \n",
       "std     12110.011237  \n",
       "min      1121.873900  \n",
       "25%      4740.287150  \n",
       "50%      9382.033000  \n",
       "75%     16639.912515  \n",
       "max     63770.428010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')     #quick descriptive stats of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we shall do is sort the columns into numerical and categorical features, as we will apply different pre-processing steps to each group.\n",
    "\n",
    "- numerical - We shall just apply a standard scaler.\n",
    "- categorical - We shall one-hot-encode the different groups dropping the first one\n",
    "\n",
    "Obviously in a real world situation we might have to be a bit more careful with what transformations we apply, potentially different ones to each columns. But for the purposes of this demo/exercise it will surfice. We care more about the process rather than the quailty of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features=[]                         #init an empty list to hold the numerical features\n",
    "catigorical_features=[]                     #init an empty list to hold the categorical features\n",
    "for col in df.columns[:-1]:                 #for each of our input features\n",
    "    if df[col].dtype == 'O':                #if its an 'object' datatype\n",
    "        catigorical_features.append(col)    #add it to our categorical features list\n",
    "    else:                                   #if its not an object\n",
    "        numeric_features.append(col)        #add it to numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'bmi', 'children']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'smoker', 'region']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catigorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[('scaler', StandardScaler())])                   #set the numerical transformer\n",
    "catigorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(drop='if_binary'))])  #set the categorical transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the column transformer\n",
    "colum_transformer = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_transformer, numeric_features),\n",
    "        ('cat', catigorical_transformer, catigorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above column transformer will then apply the transformations to the respective columns.\n",
    "\n",
    "Below, we combine this in a pipline with a linear regssion model. Any data that is recieved will have the columns transformations applied first and then the resulting transformed data will be passed to the model for what ever function was called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the final pipline\n",
    "reg = Pipeline(steps=[('columnTransform', colum_transformer),\n",
    "                      ('regression', LinearRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we now fit the model to our data remembering to separate out the last column as thats our target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columnTransform',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'bmi', 'children']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(drop='if_binary'))]),\n",
       "                                                  ['sex', 'smoker',\n",
       "                                                   'region'])])),\n",
       "                ('regression', LinearRegression())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(df.iloc[:,:-1],df.iloc[:,-1])            #fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3607.47273619,  2067.69196584,   572.99820995,  -131.3143594 ,\n",
       "       23848.53454191,   587.00923503,   234.0453356 ,  -448.01281436,\n",
       "        -373.04175627])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.named_steps['regression'].coef_             #show the coefficents to check its been trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCols = list(df.columns[:-1])     #save the name of the input features to a var for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export pipline & Test load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to create API and docker images that utilize a model the model have to be saved as a file type that it can read correctly. The simplest way to save it as a pickle file. \n",
    "\n",
    "Note this notebook is in a folder called notebooks, we are saving it in a folder called data which is on the same level as notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is saving\n",
    "pickle.dump(reg, open('../data/pipline.pickle', 'wb'))\n",
    "pickle.dump(dataCols, open('../data/columnNames.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is loading\n",
    "reg2 = pickle.load(open('../data/pipline.pickle', 'rb'))\n",
    "dataCols = pickle.load(open('../data/columnNames.pickle', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that there has been no corruption in data, we loaded the model into a different variable and we check the coefficents, they should be the same as the ones that were displayed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3607.47273619,  2067.69196584,   572.99820995,  -131.3143594 ,\n",
       "       23848.53454191,   587.00923503,   234.0453356 ,  -448.01281436,\n",
       "        -373.04175627])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2.named_steps['regression'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction for API verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, once the API is running we shall be atempting to make calls to it and getting a prediction back. To verify the answer we are getting back is correct we shall create the test example here and get the prediction for it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()     #view the data to remind us of what its meant to look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age   sex bmi children smoker     region\n",
       "0  28  male  30        0     no  northwest"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the test example\n",
    "test = pd.DataFrame(np.array([[28,'male',30,0,'no','northwest']]),columns=dataCols)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4944.96464438397]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reg2.predict(test)) #give the test example to the model to predict on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now when ever we attempt to hit our API with the test example we expect it to return the above value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the flask app file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build the .py file that will handel the API calls.\n",
    "\n",
    "Two bits of note:\n",
    "- When in a jupyter nb to write a contents of a cell to a .py file put '%%writefile filename.py' at the top of a cell\n",
    "- When the file .py file is being run it will be launched at the same level as the folders so any imports/opening of files will need to be done from this level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../app.py                            \n",
    "from flask import Flask,request, jsonify         #imports the core functionalities for running the APIs\n",
    "import traceback                                 #will handle the formatting of any erros coming from functions (OPTIONAL)\n",
    "import pickle as p                               #needed for the loading of any files i.e our pipline we wish to operate\n",
    "import pandas as pd                              #needed for giving the data to our pipline\n",
    "import json                                      #needed for handeling the json data in the request/curl\n",
    "\n",
    "app = Flask(__name__)                            #This initialises the app. Do not change the __name__\n",
    "\n",
    "@app.route('/predict', methods=['POST'])         #This sets up the route to activate the following function and the method that it will recieve \n",
    "def predict():\n",
    "    if reg:                                                     #If the pipline exists\n",
    "        try:                                                    #try to\n",
    "            json_ = request.json                                #extract the json data from the request\n",
    "            query = pd.DataFrame(json_)                         #load it into a pandas data frame\n",
    "            prediction = reg.predict(query)                     #give the data to our pipline to predict on\n",
    "            return jsonify({'prediction': list(prediction)})    #return the resulting prediction in a json formatt\n",
    "        except:                                                 #if it failed to predict\n",
    "            return jsonify({'trace': traceback.format_exc()})   #return the traceback error in json format\n",
    "    else:                                                       #if the pipline does not exist\n",
    "        print ('Train the model first')\n",
    "        return ('No model here to use')                         #return the information\n",
    "\n",
    "\n",
    "if __name__ == '__main__':                           #when the app first launches it will run the \"__main__\" body first to set anything up.\n",
    "    reg = p.load(open('data/pipline.pickle', 'rb'))  #load in our pipline otherwise nothing will happen\n",
    "    print('model loaded')\n",
    "    app.run(host='0.0.0.0',port=5000)                #tell the app to run setting the host and the port number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add more routes and funkier functions, such as pulling in data from an external database, as long as they are all written within the same cell that'll be written to the .py file. I also think that routes and functions can only be paired 1-1.\n",
    "\n",
    "Make sure you note the port that you set as this will be needed when you create the dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CLI navigate to where the above app.py file is and then start the service running by excuting:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test hitting the running API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the service running we can test it out! When the service starts it'll give you the url that it is running on, but it should be the same as the one we have entered. Now lets make a request to it with our test example and hopefully it should give us the prediction we are expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> {\"prediction\":[4944.96464438397]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://0.0.0.0:5000/predict'\n",
    "j_data = json.dumps([dict(zip(dataCols,[28,'male',30.0,0,'no','northwest']))])\n",
    "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "\n",
    "r = requests.post(url, data=j_data, headers=headers)\n",
    "print(r, r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOM! There we are, we are running our app locally and we have successfully made an API call to it! Make sure to go back to the CLI and stop the running file using ctrl-c\n",
    "\n",
    "Now to package it all up so we can fully share it to anyone and/or deploy in on the internet somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Make a docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 main steps to making the docker image.\n",
    " - Making the main .py file that does all the functionality - which we have already made\n",
    " - Making the requirements.txt file\n",
    " - Writing a Docker image (Dockerfile)\n",
    " - Building the Dockerfile\n",
    " - Push to dockerhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the requirments.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requirments.txt file is a simple list of all the libraries that you would need to pip install to be able to run the main .py file AND anything that it imports. In other words because we are using a sklearn model/pipline that needs to be included too.\n",
    "\n",
    "You can either use a text editor to write the file or you can run the cell below to make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../requirements.txt\n",
    "flask\n",
    "pandas\n",
    "sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of requirements.txt file can be checked by running the second cell below. This is wise to do incase you have included any libraries that come with python as standard. If you do, you would get the following error message."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
    "ERROR: No matching distribution found for json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: pandas in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: sklearn in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from -r ../requirements.txt (line 3)) (0.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from flask->-r ../requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from flask->-r ../requirements.txt (line 1)) (2.11.2)\n",
      "Requirement already satisfied: click>=5.1 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from flask->-r ../requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from flask->-r ../requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r ../requirements.txt (line 2)) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r ../requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r ../requirements.txt (line 2)) (2020.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from sklearn->-r ../requirements.txt (line 3)) (0.23.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.10.1->flask->-r ../requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas->-r ../requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn->-r ../requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn->-r ../requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/James.Strudwick@ibm.com/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn->-r ../requirements.txt (line 3)) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a Docker image (Dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence this is quite straight forward to do, its just how you structure the files within this container that you need to be wary off.\n",
    "\n",
    "The cell below is write a dockerfile for us and everything after the first line is written to the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../Dockerfile\n",
    "FROM python:3.8.3\n",
    "WORKDIR code/\n",
    "COPY requirements.txt .\n",
    "RUN pip3 -q install pip --upgrade\n",
    "RUN pip install -r requirements.txt\n",
    "COPY app.py .\n",
    "COPY data/pipline.pickle data/\n",
    "EXPOSE 5000\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps for this goes:\n",
    " - start from a base image\n",
    " - set up a working directory\n",
    " - copy across our requirements.txt and then pip install them to make sure we have all the libraries that we need\n",
    " - copy across the files and data that we need. Note that the pipline file is put into a subfolder called data mimicing our local file structure. Recall that our .py file loads in the data from a folder called data, we need to replicate this for it to work\n",
    " - EXPOSE the port that we wrote into our .py file\n",
    " - run the comand \"python app.py\" this will be what will launch our service\n",
    "\n",
    "and thats it! Once the above cell is run the dockerfile is written now it just remains to be built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builing the Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways we can do this:\n",
    " - Put your work on github and then you can link it to dockerhub. When you do this you can set dockerhub to watch a repo & a branch with in it, whenever the branch is pushed to, it will trigger the build process and automatical build the docker image for you from the Dockerfile in that branch. (Personally, this is my fav and it minimise CLI time)\n",
    " - Or you can build it all locally using CLI comands and then, optionally, push it to dockerhub for safe keeping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CLI navigate to the folder that contains our Dockerfile and run the following command to build it"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker build -t myappimage ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all has been done correctly you'll get a message saying it has been successfully built with an image id and what it has been tagged as. \n",
    "\n",
    "If you run the cell below you can see a list of all the docker images on you machine:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to run the image run the use the template below to build the run command inputting the required values. If you have been using the settings in this nb you can use the command in the second cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker run --rm -p <port_on_container>:<port_on_local_machine> <imagename>:<tag>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker run --rm -p 5000:5000 myappimage:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now thats its running we can test it in excatly the same way as we did earlier, AND, if its all been done correctly we should get the answer that we are expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> {\"prediction\":[4944.96464438397]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://0.0.0.0:5000/predict'\n",
    "j_data = json.dumps([dict(zip(dataCols,[28,'male',30.0,0,'no','northwest']))])\n",
    "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "\n",
    "r = requests.post(url, data=j_data, headers=headers)\n",
    "print(r, r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOOOOOO!!!!! That's it! You are done! (you can stop the container running with ctrl-c) \n",
    "\n",
    "Our pipline is now built and transformed into a docker image! Now you can share that docker image with anyone and they can just run it straight on their machine and not have to worry about any setups or install. They will have everything they need and just get straight to using it. If this was being hosted and deployed on the internet somewhere then you only need to supply the docker image we built.\n",
    "\n",
    "The last semi-optional-steps would be to push this image to dockerhub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE if you wanted to run a curl command in CLI to this the pipline then you just run the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl --header \"Content-Type: application/json\" --header \"Accept-Charset: UTF-8\" --request POST --data '[{\"age\": 28, \"sex\": \"female\", \"bmi\": 30.0, \"children\": 0, \"smoker\": \"no\", \"region\": \"northwest\"}]' \"http://0.0.0.0:5000/predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to dockerhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are pushing to dockerhub make sure you go and make a free account, and within that account make a repo (private or public) for us to store this image in.\n",
    "\n",
    "First you need to appropriatly tag the image. You'll need the image id for this which you can get from running \"docker images\" then build the following command and run it:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker tag <imageId> <username>/<repo>:<anyTagYouWantToGiveIt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've tagged it then you push it to the repo by building and running the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker push <username>/<repo>:<theTagYouGaveIt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy lemon squeezy. If anyone wanted to pull the image they would then just run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker pull <username>/<repo>:<theTagYouGaveIt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats it, we are done, we have successfully built a skl pipline, built an api for it, put it into a docker image and pushed it to dockerhub to share it with anyone.\n",
    "\n",
    "If you do ever deploy it on the internet and want to make calls to it then you only need to change \"http://0.0.0.0:5000/\" to whatever the website is.\n",
    "\n",
    "Special thanks to Junaid Butt (he doesn't want any questions please) for making me realise the power of dockerimages, he also has a nice reference for docker commands: https://paper.dropbox.com/doc/Docker-Commands--A8dM2emiEqwCDDCD2PnVHc5XAg-IL47J9mwFMg67Lmn0vKaC\n",
    "\n",
    "Dr J. Strudwick"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
